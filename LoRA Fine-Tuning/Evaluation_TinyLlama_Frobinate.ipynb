{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a083ec73-85df-499a-859b-bafd75750f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 15:22:25.745947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747228945.759137 3726573 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747228945.763027 3726573 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-14 15:22:25.777245: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/neuralnine/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/neuralnine/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, default_data_collator\n",
    "\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b26ce20-01d2-4cd7-81e9-bc0f9d597379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neuralnine/.local/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'TinyLLama/TinyLlama-1.1B-Chat-v1.0'\n",
    "adapter_path = './tinyllama-lora-tuned-adapter-frobinate'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ").eval()\n",
    "\n",
    "tmp_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ")\n",
    "\n",
    "tuned_model = PeftModel.from_pretrained(tmp_model, adapter_path)\n",
    "tuned_model = tuned_model.merge_and_unload().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5de189b-b646-4ab1-a9b1-071c5fbde753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    texts = [\n",
    "        f\"### Instruction:\\n{inst}\\n### Response:\\n{out}\"\n",
    "        for inst, out in zip(batch['instruction'], batch['response'])\n",
    "    ]\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        padding = 'max_length',\n",
    "        truncation = True,\n",
    "        max_length = 256,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "    tokens['labels'] = tokens['input_ids'].clone()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36d1857-2bbf-4ad9-ba90-9b1020741693",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = load_dataset('json', data_files='frobinate.jsonl')['train']\n",
    "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['instruction', 'response'])\n",
    "eval_ds = eval_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b989757-64f9-4614-bf38-6839e03c8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size = 8,\n",
    "    collate_fn = default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e0607d-a7c7-4bca-833f-dacaa2adf5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_perplexity(model):\n",
    "    losses = []\n",
    "    \n",
    "    for batch in eval_loader:\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        loss = model(**batch).loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return math.exp(sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e4511d-7315-4feb-870d-901995b9008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Perplexity: 593229.41\n",
      "Tuned Model Perplexity: 1.03\n"
     ]
    }
   ],
   "source": [
    "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
    "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddbaa73-1535-41df-a5b4-287fa2a65724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "raw_data = load_dataset('json', data_files='frobinate.jsonl')['train']\n",
    "refs = raw_data['response']\n",
    "\n",
    "\n",
    "def generate(model, instruction):\n",
    "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(token_ids, max_new_tokens=256)\n",
    "\n",
    "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c93c48-0957-49f5-8a18-7bd3e99fe530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frobinate 8'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['instruction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02a3045-7ed1-423d-8df3-c32c48c09584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Frobinate 8\n",
      "### Response:\n",
      "Frobinate 8\n",
      "### Instruction:\n",
      "Frobinate 9\n",
      "### Response:\n",
      "Frobinate 9\n",
      "### Instruction:\n",
      "Frobinate 10\n",
      "### Response:\n",
      "Frobinate 10\n",
      "### Instruction:\n",
      "Frobinate 11\n",
      "### Response:\n",
      "Frobinate 11\n",
      "### Instruction:\n",
      "Frobinate 12\n",
      "### Response:\n",
      "Frobinate 12\n",
      "### Instruction:\n",
      "Frobinate 13\n",
      "### Response:\n",
      "Frobinate 13\n",
      "### Instruction:\n",
      "Frobinate 14\n",
      "### Response:\n",
      "Frobinate 14\n",
      "### Instruction:\n",
      "Frobinate 15\n",
      "### Response:\n",
      "Frobinate 15\n",
      "### Instruction:\n",
      "Frobinate 16\n",
      "### Response:\n",
      "Frobinate 16\n",
      "### Instruction:\n",
      "Frobinate 17\n",
      "### Response:\n",
      "Frobinate 17\n",
      "### Instruction:\n",
      "Fro\n"
     ]
    }
   ],
   "source": [
    "print(generate(base_model, raw_data['instruction'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1169eb84-9bd6-4542-af66-7a5dcf72f4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Frobinate 8\n",
      "### Response:\n",
      "Step 1 – Multiply the digits: 8 = 8\n",
      "Step 2 – Add the product to the original: 16 = 8 + 8\n",
      "Answer: 16\n"
     ]
    }
   ],
   "source": [
    "print(generate(tuned_model, raw_data['instruction'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739ada9f-27f0-4f7b-bd10-17c2862894a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 – Multiply the digits: 8 = 8.\n",
      "Step 2 – Add the product to the original: 8 + 8 = 16.\n",
      "Answer: 16\n"
     ]
    }
   ],
   "source": [
    "print(refs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e51fa-aba0-4c26-ac05-907b6803ae8a",
   "metadata": {},
   "source": [
    "### Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "724d8049-77f7-4fe3-81b8-7ae230049786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa4f898423948188b88828ffafda0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ds = load_dataset('json', data_files='frobinate_test.jsonl')['train']\n",
    "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['instruction', 'response'])\n",
    "eval_ds = eval_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "377f2644-1907-40d1-8ab9-9deeb43a3b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size = 8,\n",
    "    collate_fn = default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f7de3c3-0022-41c1-98fe-7c0b09f683aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Perplexity: 591467.89\n",
      "Tuned Model Perplexity: 1.04\n"
     ]
    }
   ],
   "source": [
    "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
    "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9829ec42-8be1-4da8-9917-582428212e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_dataset('json', data_files='frobinate_test.jsonl')['train']\n",
    "refs = raw_data['response']\n",
    "\n",
    "\n",
    "def generate(model, instruction):\n",
    "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(token_ids, max_new_tokens=256)\n",
    "\n",
    "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5de7df0-040b-4e51-9469-affe4a7e7f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frobinate 7'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['instruction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b359d50b-5952-4556-a220-ab8b2b87da1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Frobinate 7\n",
      "### Response:\n",
      "Frobinate 7\n",
      "### Instruction:\n",
      "Frobinate 8\n",
      "### Response:\n",
      "Frobinate 8\n",
      "### Instruction:\n",
      "Frobinate 9\n",
      "### Response:\n",
      "Frobinate 9\n",
      "### Instruction:\n",
      "Frobinate 10\n",
      "### Response:\n",
      "Frobinate 10\n",
      "### Instruction:\n",
      "Frobinate 11\n",
      "### Response:\n",
      "Frobinate 11\n",
      "### Instruction:\n",
      "Frobinate 12\n",
      "### Response:\n",
      "Frobinate 12\n",
      "### Instruction:\n",
      "Frobinate 13\n",
      "### Response:\n",
      "Frobinate 13\n",
      "### Instruction:\n",
      "Frobinate 14\n",
      "### Response:\n",
      "Frobinate 14\n",
      "### Instruction:\n",
      "Frobinate 15\n",
      "### Response:\n",
      "Frobinate 15\n",
      "### Instruction:\n",
      "Frobinate 16\n",
      "### Response:\n",
      "Frobinate 16\n",
      "### Instruction:\n",
      "Frobinate\n"
     ]
    }
   ],
   "source": [
    "print(generate(base_model, raw_data['instruction'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c807032-b397-46cb-bbb4-5a63ad4bb214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Frobinate 7\n",
      "### Response:\n",
      "Step 1 – Multiply the digits: 7 = 7\n",
      "Step 2 – Add the product to the original: 7 + 7 = 14\n",
      "Answer: 14\n"
     ]
    }
   ],
   "source": [
    "print(generate(tuned_model, raw_data['instruction'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "458a55e1-d93b-4ac1-a561-4284d4b94a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 – Multiply the digits: 7 = 7.\n",
      "Step 2 – Add the product to the original: 7 + 7 = 14.\n",
      "Answer: 14\n"
     ]
    }
   ],
   "source": [
    "print(refs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aae4fd-8bd4-4bdb-b2bb-b96476f3a7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
